# Derek Lankeaux, MS
## Machine Learning Research Engineer | LLM Evaluation Specialist | AI Safety Researcher

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-0077B5?style=for-the-badge&logo=linkedin)](https://linkedin.com/in/derek-lankeaux)
[![GitHub](https://img.shields.io/badge/GitHub-Follow-181717?style=for-the-badge&logo=github)](https://github.com/dl1413)
[![Portfolio](https://img.shields.io/badge/Portfolio-Visit-00C7B7?style=for-the-badge)](https://dl1413.github.io/LLM-Portfolio/)

---

### ğŸ¯ Machine Learning Research Engineer | Actively Seeking 2026 Opportunities

**Core Competencies:** Multi-Model LLM Evaluation â€¢ Ensemble ML Systems â€¢ Bayesian Uncertainty Quantification â€¢ Production MLOps â€¢ AI Safety Red-Teaming

> **Impact-Driven ML Research Engineer** specialized in building production-grade LLM evaluation frameworks, multi-model ensemble systems, and Bayesian inference pipelines. Proven track record of delivering **96.8-99.12% accuracy** models with rigorous statistical validation. Experienced in processing **80K+ LLM annotations** at production scale (850 samples/hr) while maintaining research-grade reliability (Krippendorff's Î± â‰¥ 0.81). Published researcher with **3 technical reports** demonstrating compliance with IEEE 2830-2025, ISO/IEC 23894:2025, and EU AI Act standards.

### ğŸ† Key Achievements for 2026 ML Research Engineer Roles

- ğŸ›¡ï¸ **Built LLM Red-Team Framework**: 3-model ensemble (GPT-4o, Claude-3.5, Llama-3.2) with 340Ã— cost reduction ($0.018/sample) and audit-grade reliability (Î± = 0.81)
- ğŸ”¬ **Developed Multi-Model Evaluation Pipeline**: Krippendorff's Î± = 0.81-0.84 across frontier LLMs with Bayesian uncertainty quantification
- ğŸ¥ **Deployed Clinical-Grade ML System**: 99.12% accuracy breast cancer classifier exceeding human expert performance (90-95%)
- ğŸ“Š **Scaled Production NLP Pipelines**: 80K+ API calls with circuit breakers, rate limiting, and MLflow experiment tracking
- âš¡ **Engineered Low-Latency Inference**: FastAPI deployments with <100ms p95 latency and real-time monitoring
- ğŸ“ˆ **Published Research-Quality Reports**: 3 technical publications with p < 0.001 significance, 95% HDI intervals, and SHAP explainability

---

## ğŸš€ Featured Research Projects

<table>
<tr>
<td width="50%" valign="top">

### ğŸ›¡ï¸ AI Safety Red-Team Evaluation
**[ğŸ“„ Technical Report](./AI_Safety_RedTeam_Evaluation_Report.md)** | **[ğŸ“Š Publication](./AI_Safety_RedTeam_Evaluation_Publication.pdf)**

**Automated harm detection using dual-stage LLM ensemble + ML classification**

#### Impact Metrics
- ğŸ¯ **12,500 AI response pairs** evaluated across 6 harm categories
- ğŸ“Š **96.8% accuracy** with Stacking Classifier (97.2% precision, 96.1% recall)
- âš¡ **340Ã— cost reduction**: $0.018/sample vs $6.12 human annotation
- ğŸ”¬ **Krippendorff's Î± = 0.81** (excellent LLM ensemble reliability)
- ğŸš€ **850 samples/hour** processing rate at production scale

#### Technical Innovation
- **Dual-Stage Framework**: LLM ensemble annotation â†’ ML classification pipeline
- **Multi-Model Risk Analysis**: Bayesian hierarchical modeling quantifying vulnerability (95% HDI)
- **47 Engineered Features**: Linguistic, semantic, and structural harm signals
- **6 Harm Categories**: Dangerous info, hate, deception, privacy, illegal activity, self-harm
- **Production MLOps**: Scalable deployment with SHAP explainability and audit trails

#### Tech Stack
`GPT-4o` `Claude-3.5` `Llama-3.2` `XGBoost` `Stacking` `PyMC` `SHAP` `MLflow` `Constitutional AI`

</td>
<td width="50%" valign="top">

### ğŸ”¬ LLM Ensemble Bias Detection
**[ğŸ“„ Technical Report](./LLM_Ensemble_Bias_Detection_Report.md)** | **[ğŸ“Š Publication](./LLM_Bias_Detection_Publication.pdf)**

**Multi-LLM framework for bias detection using Bayesian hierarchical modeling**

#### Impact Metrics
- ğŸ“Š **67,500 bias ratings** processed across 4,500 textbook passages
- ğŸ¯ **Krippendorff's Î± = 0.84** (excellent inter-rater reliability)
- ğŸ“ˆ **Statistically significant findings** (Friedman Ï‡Â² = 42.73, p < 0.001)
- âš¡ **Production-scale deployment** handling 2.5M tokens

#### Technical Innovation
- **Multi-LLM Ensemble**: GPT-4o, Claude-3.5-Sonnet, Llama-3.2 with 92% pairwise correlation
- **Bayesian Inference**: PyMC hierarchical model with partial pooling, MCMC convergence (R-hat < 1.01)
- **Statistical Rigor**: 95% HDI quantification, publisher-level credible bias detection (3/5 significant)
- **Production Engineering**: Circuit breakers, exponential backoff, MLflow tracking

#### Tech Stack
`GPT-4o` `Claude-3.5` `Llama-3.2` `PyMC` `ArviZ` `MLflow` `FastAPI` `LangChain`

</td>
</tr>
<tr>
<td width="50%" valign="top">

### ğŸ¥ Breast Cancer ML Classification
**[ğŸ“„ Technical Report](./Breast_Cancer_Classification_Report.md)** | **[ğŸ“Š Publication](./Breast_Cancer_Classification_Publication.pdf)**

**Clinical-grade ensemble system exceeding human expert performance**

#### Impact Metrics
- ğŸ† **99.12% accuracy** (best-in-class AdaBoost)
- ğŸ’¯ **100% precision** (zero false positives)
- ğŸ¯ **98.59% recall** (minimal missed cases)
- ğŸ“ˆ **ROC-AUC: 0.9987** (near-perfect discrimination)

#### Technical Innovation
- **8-Algorithm Benchmark**: Comprehensive evaluation (RF, XGBoost, LightGBM, AdaBoost, Stacking, Voting)
- **Advanced Preprocessing**: VIF multicollinearity analysis, SMOTE balancing, RFE feature selection
- **Explainable AI**: SHAP values for clinical transparency, fairness auditing (IEEE 2830-2025)
- **Production Ready**: MLflow registry, FastAPI deployment (<100ms p95 latency)

#### Tech Stack
`scikit-learn` `XGBoost` `LightGBM` `AdaBoost` `SMOTE` `SHAP` `MLflow` `FastAPI`

</td>
<td width="50%" valign="top">

### ğŸ“Š Research Impact Summary

**Cross-Project Synthesis:**
- **3 production ML systems** deployed across AI safety, bias detection, and healthcare
- **80,000+ annotations** processed via LLM ensembles with validated reliability
- **340Ã— cost efficiency** gain in AI safety evaluation vs human baseline
- **Consistent statistical rigor**: Krippendorff's Î± â‰¥ 0.81, MCMC R-hat < 1.01, p < 0.001
- **Reproducible pipelines**: MLflow tracking, versioned artifacts, IEEE 2830-2025 compliance

**Domain Expertise:**
- AI Safety & Red-Teaming
- Educational Content Analysis  
- Clinical Decision Support
- Responsible AI Governance
- Production MLOps at Scale

</td>
</tr>
</table>

---

## ğŸ’¼ Professional Experience & Capabilities

### ğŸ¯ Core Expertise

<table>
<tr>
<td width="33%" valign="top">

#### ğŸ¤– LLM & AI Safety
- Multi-model ensemble architectures
- AI safety red-team evaluation
- Prompt engineering & optimization
- Inter-rater reliability analysis
- Harm detection & classification
- API integration at scale

**Tools:** GPT-4o, Claude-3.5, Llama-3.2, HuggingFace, LangChain, Constitutional AI

</td>
<td width="33%" valign="top">

#### ğŸ“Š Statistical ML
- Ensemble methods (8+ algorithms)
- Bayesian hierarchical modeling
- MCMC diagnostics (R-hat, ESS)
- Hypothesis testing & validation
- Feature engineering & selection

**Tools:** PyMC, ArviZ, scikit-learn, XGBoost, LightGBM

</td>
<td width="33%" valign="top">

#### âš™ï¸ Production MLOps
- FastAPI model deployment
- MLflow experiment tracking
- Circuit breakers & rate limiting
- Monitoring & drift detection
- Docker/Kubernetes orchestration

**Tools:** MLflow, FastAPI, Docker, Redis, Prometheus

</td>
</tr>
</table>

### ğŸ› ï¸ Technical Stack

```yaml
Languages:        Python 3.12+ â€¢ R â€¢ SQL â€¢ Bash
ML Frameworks:    PyTorch 2.0+ â€¢ TensorFlow 2.15+ â€¢ scikit-learn 1.5+ â€¢ JAX
LLM APIs:         OpenAI (GPT-4o) â€¢ Anthropic (Claude-3.5) â€¢ Meta (Llama-3.2) â€¢ HuggingFace
Ensemble ML:      XGBoost 2.1+ â€¢ LightGBM 4.5+ â€¢ CatBoost â€¢ AdaBoost
Bayesian Stats:   PyMC 5.15+ â€¢ ArviZ 0.18+ â€¢ NumPyro â€¢ Stan â€¢ JAGS
Data Stack:       Pandas 2.2+ â€¢ Polars 1.0+ â€¢ NumPy 2.0+ â€¢ Dask â€¢ Apache Arrow
MLOps:            MLflow 2.15+ â€¢ Weights & Biases â€¢ DVC â€¢ Kubeflow
Deployment:       FastAPI 0.110+ â€¢ Docker â€¢ Kubernetes â€¢ AWS â€¢ GCP
Monitoring:       Prometheus â€¢ Grafana â€¢ ELK Stack â€¢ Datadog
Explainability:   SHAP â€¢ LIME â€¢ Captum â€¢ InterpretML
Version Control:  Git â€¢ GitHub Actions â€¢ GitLab CI/CD
```

### ğŸ”¬ Research Methodology

**Statistical Rigor**
- âœ… Cross-validation (k-fold, stratified, leave-one-out)
- âœ… Bayesian inference with credible intervals (95% HDI)
- âœ… Multiple testing correction (Bonferroni, FDR, Holm-Sidak)
- âœ… Effect size reporting (Cohen's d, Î·Â², Cramer's V)
- âœ… Power analysis and sample size determination

**Reproducibility Standards**
- âœ… IEEE 2830-2025 (Transparent ML) compliance
- âœ… ISO/IEC 23894:2025 (AI Risk Management) alignment
- âœ… Fixed random seeds and version pinning
- âœ… Comprehensive model cards and documentation
- âœ… Carbon footprint tracking and reporting

**Production Engineering**
- âœ… Robust error handling and circuit breakers
- âœ… Adaptive rate limiting and backoff strategies
- âœ… Comprehensive logging (structlog) and monitoring
- âœ… A/B testing frameworks and gradual rollouts
- âœ… Model performance tracking and drift detection

---

## ğŸ“Š Quantitative Performance Summary

<table>
<tr>
<td width="33%" valign="top">

### AI Safety Red-Team
| Metric | Value | Benchmark |
|--------|-------|-----------|
| **Accuracy** | 96.8% | High reliability |
| **Precision** | 97.2% | Low false alarms |
| **Recall** | 96.1% | Comprehensive detection |
| **ROC-AUC** | 0.9923 | Near-perfect |
| **LLM Reliability** | Î± = 0.81 | Excellent (â‰¥0.80) |
| **Cost Reduction** | 340Ã— | $0.018/sample |
| **Throughput** | 850/hr | Production scale |

</td>
<td width="33%" valign="top">

### LLM Bias Detection
| Metric | Value | Benchmark |
|--------|-------|-----------|
| **Inter-Rater Reliability** | Î± = 0.84 | Excellent (â‰¥0.80) |
| **Model Convergence** | R-hat < 1.01 | Perfect |
| **Statistical Power** | Ï‡Â² = 42.73 | p < 0.001 |
| **Scale Deployment** | 67.5K ratings | Production |
| **Credible Findings** | 3/5 publishers | 60% detection |

</td>
<td width="33%" valign="top">

### Breast Cancer ML
| Metric | Value | Benchmark |
|--------|-------|-----------|
| **Accuracy** | 99.12% | Exceeds human (90-95%) |
| **Precision** | 100.00% | Zero false positives |
| **Recall** | 98.59% | Minimal misses |
| **ROC-AUC** | 0.9987 | Near-perfect |
| **CV Stability** | 98.46% Â± 1.12% | Robust |

</td>
</tr>
</table>

---

## ğŸ“ Education & Certifications

**Master of Science in Applied Statistics**  
Rochester Institute of Technology | Expected 2026  
*Specialization: Bayesian Methods, Machine Learning, Experimental Design*

**Relevant Coursework:**
- Advanced Bayesian Inference & MCMC Methods
- Deep Learning & Neural Networks
- Statistical Learning Theory
- Experimental Design & Causal Inference
- High-Dimensional Statistics
- Computational Statistics & Optimization

---

## ğŸ’¼ Target Opportunities (2026 Machine Learning Research Engineer)

### ğŸ¯ Ideal Roles

<table>
<tr>
<td width="50%">

**Machine Learning Research Engineer**
- LLM evaluation & benchmarking systems
- Multi-model ensemble architectures
- Foundation model red-teaming
- Production ML pipeline development
- Model performance optimization

</td>
<td width="50%">

**ML Systems Engineer**
- Scalable inference infrastructure
- MLOps platform development
- Real-time model serving (<100ms)
- Distributed training pipelines
- Monitoring & observability

</td>
</tr>
<tr>
<td width="50%">

**Applied Research Scientist**
- Bayesian uncertainty quantification
- Ensemble learning methodologies
- Statistical validation frameworks
- Experimental design & analysis
- Publication-ready research

</td>
<td width="50%">

**AI Safety Research Engineer**
- Red-team evaluation frameworks
- Harm detection & classification
- Model alignment research
- Responsible AI governance
- Compliance (IEEE 2830-2025, EU AI Act)

</td>
</tr>
</table>

### ğŸŒŸ What I Bring to 2026 ML Research Engineering Roles

âœ… **LLM Expertise**: Multi-model ensemble systems (GPT-4o, Claude-3.5, Llama-3.2) with validated reliability (Î± â‰¥ 0.81)  
âœ… **Production ML**: FastAPI deployments processing 850 samples/hr with <100ms p95 latency  
âœ… **Statistical Rigor**: Bayesian inference, hypothesis testing, 95% HDI quantification (p < 0.001)  
âœ… **AI Safety**: Pioneered 340Ã— cost-efficient red-team framework with 6-category harm taxonomy  
âœ… **Research Quality**: 3 technical reports with IEEE 2830-2025 and EU AI Act compliance  
âœ… **MLOps Maturity**: MLflow tracking, model versioning, circuit breakers, monitoring infrastructure  
âœ… **Proven Impact**: Clinical-grade ML (99.12% accuracy) exceeding human expert performance

---

## ğŸ“š Publications & Technical Reports

| Title | Type | Date | Links |
|-------|------|------|-------|
| **AI Safety Red-Team Evaluation** | Technical Report v1.0.0 | Jan 2026 | [Report](./AI_Safety_RedTeam_Evaluation_Report.md) â€¢ [PDF](./AI_Safety_RedTeam_Evaluation_Publication.pdf) |
| **LLM Ensemble Textbook Bias Detection** | Technical Report v3.0.0 | Jan 2026 | [Report](./LLM_Ensemble_Bias_Detection_Report.md) â€¢ [PDF](./LLM_Bias_Detection_Publication.pdf) |
| **Breast Cancer Classification** | Technical Report v3.0.0 | Jan 2026 | [Report](./Breast_Cancer_Classification_Report.md) â€¢ [PDF](./Breast_Cancer_Classification_Publication.pdf) |

---

## ğŸ“« Let's Connect

<div align="center">

### ğŸ¤ Open to Research Engineer Opportunities | Available for Interviews

**Preferred Contact:** [LinkedIn](https://linkedin.com/in/derek-lankeaux) â€¢ Email Available Upon Request

[![LinkedIn](https://img.shields.io/badge/LinkedIn-Derek_Lankeaux-0077B5?style=for-the-badge&logo=linkedin)](https://linkedin.com/in/derek-lankeaux)
[![GitHub](https://img.shields.io/badge/GitHub-@dl1413-181717?style=for-the-badge&logo=github)](https://github.com/dl1413)
[![Portfolio](https://img.shields.io/badge/Portfolio-Live_Site-00C7B7?style=for-the-badge)](https://dl1413.github.io/LLM-Portfolio/)

**Location:** Available for remote/hybrid positions  
**Timeline:** Seeking positions starting 2026  
**Visa Status:** Authorized to work in the United States

</div>

---

<div align="center">

## ğŸ› ï¸ Repository Structure

```
Machine-Learning-Research-Engineering-Project-Profile/
â”œâ”€â”€ ğŸ“„ README.md                                      # This portfolio
â”œâ”€â”€ ğŸ›¡ï¸ AI_Safety_RedTeam_Evaluation_Report.md        # AI safety report
â”œâ”€â”€ ğŸ“‘ AI_Safety_RedTeam_Evaluation_Publication.pdf  # Publication PDF
â”œâ”€â”€ ğŸ“Š Breast_Cancer_Classification_Report.md        # ML technical report
â”œâ”€â”€ ğŸ“‘ Breast_Cancer_Classification_Publication.pdf  # Publication PDF
â”œâ”€â”€ ğŸ”¬ LLM_Ensemble_Bias_Detection_Report.md         # LLM research report
â””â”€â”€ ğŸ“‘ LLM_Bias_Detection_Publication.pdf            # Publication PDF
```

---

### ğŸ” Keywords for Search & ATS

</div>

**Machine Learning:** Deep Learning â€¢ Neural Networks â€¢ Ensemble Methods â€¢ Random Forest â€¢ XGBoost â€¢ LightGBM â€¢ AdaBoost â€¢ Gradient Boosting â€¢ Stacking â€¢ Bagging â€¢ Feature Engineering

**Large Language Models:** GPT-4 â€¢ GPT-4o â€¢ Claude-3.5-Sonnet â€¢ Llama-3.2 â€¢ BERT â€¢ Transformers â€¢ Prompt Engineering â€¢ Few-Shot Learning â€¢ Zero-Shot Learning â€¢ In-Context Learning â€¢ Constitutional AI

**AI Safety & Red-Teaming:** Harm Detection â€¢ Adversarial Testing â€¢ Safety Evaluation â€¢ Red Team â€¢ Jailbreak Detection â€¢ Model Alignment â€¢ RLHF â€¢ Constitutional AI â€¢ Safety Benchmarking â€¢ Vulnerability Assessment

**Bayesian Statistics:** Hierarchical Modeling â€¢ MCMC â€¢ PyMC â€¢ Stan â€¢ Posterior Inference â€¢ Prior Specification â€¢ Credible Intervals â€¢ Bayesian Inference â€¢ Probabilistic Programming â€¢ HDI

**Statistical Methods:** Hypothesis Testing â€¢ Cross-Validation â€¢ Bootstrap â€¢ Permutation Testing â€¢ Effect Sizes â€¢ Power Analysis â€¢ Multiple Testing Correction â€¢ Inter-Rater Reliability â€¢ Krippendorff's Alpha â€¢ Cohen's Kappa

**Explainable AI (XAI):** SHAP â€¢ LIME â€¢ Feature Importance â€¢ Model Interpretability â€¢ Fairness Auditing â€¢ Bias Detection â€¢ Responsible AI â€¢ AI Ethics â€¢ AI Governance â€¢ Audit Trails

**MLOps & Production:** MLflow â€¢ Weights & Biases â€¢ Model Registry â€¢ Experiment Tracking â€¢ FastAPI â€¢ Docker â€¢ Kubernetes â€¢ CI/CD â€¢ Model Monitoring â€¢ Drift Detection â€¢ A/B Testing â€¢ Circuit Breakers

**Programming:** Python â€¢ R â€¢ SQL â€¢ PyTorch â€¢ TensorFlow â€¢ scikit-learn â€¢ Pandas â€¢ NumPy â€¢ Dask â€¢ Apache Spark

**Research Engineering:** Technical Writing â€¢ Statistical Validation â€¢ Reproducible Research â€¢ Peer Review â€¢ Literature Review â€¢ Experimental Design â€¢ Causal Inference â€¢ Cost-Benefit Analysis

**AI Safety Domains:** Dangerous Information â€¢ Hate Speech â€¢ Deception Detection â€¢ Privacy Violation â€¢ Illegal Activity â€¢ Self-Harm Prevention â€¢ Content Moderation â€¢ Trust & Safety

**Standards & Compliance:** IEEE 2830-2025 â€¢ ISO/IEC 23894:2025 â€¢ EU AI Act â€¢ GDPR â€¢ Model Cards â€¢ Transparency â€¢ Accountability â€¢ AI Governance

---

<div align="center">

**ğŸ“Œ Last Updated:** January 2026  
**âœ… Compliance:** IEEE 2830-2025 (Transparent ML) â€¢ ISO/IEC 23894:2025 (AI Risk Management)  
**ğŸ”’ License:** Portfolio content Â© 2026 Derek Lankeaux. Code samples available under MIT License.

---

*â­ If you find this work interesting, please star this repository!*

</div>
